{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando requisitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando uma imagem RGB aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example RGB image as a numpy array (shape: (100, 100, 3))\n",
    "rgb_image = np.random.rand(100, 100, 3) * 255  # Random image for illustration\n",
    "rgb_image = rgb_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessando a imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocess the image\n",
    "def preprocess_image(image):\n",
    "    # Ensure the image is a numpy array\n",
    "    if isinstance(image, np.ndarray):\n",
    "        # Normalize image (assuming the image is in the range [0, 255])\n",
    "        image = image / 255.0\n",
    "    else:\n",
    "        raise ValueError(\"The image should be a numpy array.\")\n",
    "    \n",
    "    # Convert image to a tensor and add batch dimension\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    image = tf.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_image = preprocess_image(rgb_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando o label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prepare the label\n",
    "# Example label for classification (assuming 10 classes)\n",
    "label = 3  # Example label\n",
    "num_classes = 10\n",
    "label = to_categorical(label, num_classes=num_classes)  # One-hot encode the label\n",
    "label = tf.convert_to_tensor(label, dtype=tf.float32)\n",
    "label = tf.expand_dims(label, axis=0)  # Add batch dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create the model\n",
    "input_tensor = Input(shape=(100, 100, 3))\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Add global average pooling layer\n",
    "x = Dense(1024, activation='relu')(x)  # Add a fully connected layer\n",
    "predictions = Dense(num_classes, activation='softmax')(x)  # Add output layer\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Optionally, freeze the base model layers to fine-tune only the top layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 0.0000e+00 - loss: 2.7906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f2374517ac0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Train the model\n",
    "model.fit(preprocessed_image, label, epochs=1)  # Train on the single image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Functional name=functional_3, built=True>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100, 100, 3), dtype=float32, numpy=\n",
       "array([[[[0.56078434, 0.48235294, 0.6431373 ],\n",
       "         [0.60784316, 0.85490197, 0.7176471 ],\n",
       "         [0.78039217, 0.46666667, 0.11764706],\n",
       "         ...,\n",
       "         [0.89411765, 0.654902  , 0.8235294 ],\n",
       "         [0.07843138, 0.60784316, 0.16862746],\n",
       "         [0.03921569, 0.43529412, 0.8117647 ]],\n",
       "\n",
       "        [[0.11764706, 0.32941177, 0.4627451 ],\n",
       "         [0.5254902 , 0.13725491, 0.38431373],\n",
       "         [0.9529412 , 0.5176471 , 0.3372549 ],\n",
       "         ...,\n",
       "         [0.9137255 , 0.5176471 , 0.03921569],\n",
       "         [0.6392157 , 0.8       , 0.99607843],\n",
       "         [0.40392157, 0.8666667 , 0.38431373]],\n",
       "\n",
       "        [[0.10196079, 0.08627451, 0.10588235],\n",
       "         [0.49019608, 0.90588236, 0.76862746],\n",
       "         [0.9764706 , 0.11372549, 0.5647059 ],\n",
       "         ...,\n",
       "         [0.7176471 , 0.4392157 , 0.7607843 ],\n",
       "         [0.29411766, 0.1882353 , 0.9019608 ],\n",
       "         [0.9490196 , 0.95686275, 0.21176471]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.12941177, 0.8235294 , 0.9137255 ],\n",
       "         [0.6627451 , 0.25490198, 0.28627452],\n",
       "         [0.56078434, 0.47843137, 0.93333334],\n",
       "         ...,\n",
       "         [0.14117648, 0.46666667, 0.15686275],\n",
       "         [0.14509805, 0.83137256, 0.00784314],\n",
       "         [0.80784315, 0.32941177, 0.9411765 ]],\n",
       "\n",
       "        [[0.8       , 0.40784314, 0.9254902 ],\n",
       "         [0.54901963, 0.9019608 , 0.56078434],\n",
       "         [0.32941177, 0.09019608, 0.29803923],\n",
       "         ...,\n",
       "         [0.62352943, 0.12941177, 0.28235295],\n",
       "         [0.92156863, 0.39215687, 0.7019608 ],\n",
       "         [0.13725491, 0.34117648, 0.99215686]],\n",
       "\n",
       "        [[0.        , 0.5137255 , 0.6       ],\n",
       "         [0.2509804 , 0.85490197, 0.98039216],\n",
       "         [0.8745098 , 0.47843137, 0.2901961 ],\n",
       "         ...,\n",
       "         [0.21568628, 0.62352943, 0.        ],\n",
       "         [0.4509804 , 0.02352941, 0.23137255],\n",
       "         [0.3254902 , 0.70980394, 0.07450981]]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
