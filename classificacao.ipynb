{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalando requisitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T22:07:27.369378Z",
     "start_time": "2024-05-27T22:07:11.311269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/mnt/home/henrique/Repositorios_Git/GitHub.com/Henriquemcc/Ciencia da Computacao/Trabalho_Pratico_-_Processamento_e_Analise_de_Imagens_-_2024-1/develop_henrique_2024_05_27/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/mnt/home/henrique/Repositorios_Git/GitHub.com/Henriquemcc/Ciencia da Computacao/Trabalho_Pratico_-_Processamento_e_Analise_de_Imagens_-_2024-1/develop_henrique_2024_05_27/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/mnt/home/henrique/Repositorios_Git/GitHub.com/Henriquemcc/Ciencia da Computacao/Trabalho_Pratico_-_Processamento_e_Analise_de_Imagens_-_2024-1/develop_henrique_2024_05_27/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/mnt/home/henrique/Repositorios_Git/GitHub.com/Henriquemcc/Ciencia da Computacao/Trabalho_Pratico_-_Processamento_e_Analise_de_Imagens_-_2024-1/develop_henrique_2024_05_27/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/mnt/home/henrique/Repositorios_Git/GitHub.com/Henriquemcc/Ciencia da Computacao/Trabalho_Pratico_-_Processamento_e_Analise_de_Imagens_-_2024-1/develop_henrique_2024_05_27/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ./app/requirements.txt -q\n",
    "%pip install pandas -q\n",
    "%pip install scikit-learn -q\n",
    "%pip install tensorflow -q\n",
    "%pip install numpy -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando requisitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T22:07:32.150174Z",
     "start_time": "2024-05-27T22:07:27.372735Z"
    }
   },
   "outputs": [],
   "source": [
    "from app.modelo.imagem_rgb import ImagemRGB\n",
    "import sklearn.model_selection\n",
    "import pandas\n",
    "import tensorflow\n",
    "import os\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = os.path.join(os.getcwd(), 'dataset_converted')\n",
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrindo base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T22:07:32.178614Z",
     "start_time": "2024-05-27T22:07:32.152120Z"
    }
   },
   "outputs": [],
   "source": [
    "data_frame = pandas.read_csv(\"classifications.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T22:07:32.206294Z",
     "start_time": "2024-05-27T22:07:32.182697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_filename</th>\n",
       "      <th>image_doi</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>bethesda_system</th>\n",
       "      <th>nucleus_x</th>\n",
       "      <th>nucleus_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400</td>\n",
       "      <td>9ae8a4edde40219bad6303cebc672ee4.png</td>\n",
       "      <td>10.6084/m9.figshare.12230906</td>\n",
       "      <td>1</td>\n",
       "      <td>SCC</td>\n",
       "      <td>792</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400</td>\n",
       "      <td>9ae8a4edde40219bad6303cebc672ee4.png</td>\n",
       "      <td>10.6084/m9.figshare.12230906</td>\n",
       "      <td>2</td>\n",
       "      <td>SCC</td>\n",
       "      <td>601</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400</td>\n",
       "      <td>9ae8a4edde40219bad6303cebc672ee4.png</td>\n",
       "      <td>10.6084/m9.figshare.12230906</td>\n",
       "      <td>3</td>\n",
       "      <td>SCC</td>\n",
       "      <td>363</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>9ae8a4edde40219bad6303cebc672ee4.png</td>\n",
       "      <td>10.6084/m9.figshare.12230906</td>\n",
       "      <td>4</td>\n",
       "      <td>SCC</td>\n",
       "      <td>599</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>9ae8a4edde40219bad6303cebc672ee4.png</td>\n",
       "      <td>10.6084/m9.figshare.12230906</td>\n",
       "      <td>5</td>\n",
       "      <td>Negative for intraepithelial lesion</td>\n",
       "      <td>1186</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11529</th>\n",
       "      <td>1</td>\n",
       "      <td>be340ee72689dfe3f8dc9c24de6127f4.png</td>\n",
       "      <td>10.6084/m9.figshare.12229511</td>\n",
       "      <td>11530</td>\n",
       "      <td>LSIL</td>\n",
       "      <td>618</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11530</th>\n",
       "      <td>1</td>\n",
       "      <td>be340ee72689dfe3f8dc9c24de6127f4.png</td>\n",
       "      <td>10.6084/m9.figshare.12229511</td>\n",
       "      <td>11531</td>\n",
       "      <td>LSIL</td>\n",
       "      <td>607</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11531</th>\n",
       "      <td>1</td>\n",
       "      <td>be340ee72689dfe3f8dc9c24de6127f4.png</td>\n",
       "      <td>10.6084/m9.figshare.12229511</td>\n",
       "      <td>11532</td>\n",
       "      <td>LSIL</td>\n",
       "      <td>707</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11532</th>\n",
       "      <td>1</td>\n",
       "      <td>be340ee72689dfe3f8dc9c24de6127f4.png</td>\n",
       "      <td>10.6084/m9.figshare.12229511</td>\n",
       "      <td>11533</td>\n",
       "      <td>LSIL</td>\n",
       "      <td>579</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11533</th>\n",
       "      <td>1</td>\n",
       "      <td>be340ee72689dfe3f8dc9c24de6127f4.png</td>\n",
       "      <td>10.6084/m9.figshare.12229511</td>\n",
       "      <td>11534</td>\n",
       "      <td>Negative for intraepithelial lesion</td>\n",
       "      <td>227</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11534 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                        image_filename  \\\n",
       "0           400  9ae8a4edde40219bad6303cebc672ee4.png   \n",
       "1           400  9ae8a4edde40219bad6303cebc672ee4.png   \n",
       "2           400  9ae8a4edde40219bad6303cebc672ee4.png   \n",
       "3           400  9ae8a4edde40219bad6303cebc672ee4.png   \n",
       "4           400  9ae8a4edde40219bad6303cebc672ee4.png   \n",
       "...         ...                                   ...   \n",
       "11529         1  be340ee72689dfe3f8dc9c24de6127f4.png   \n",
       "11530         1  be340ee72689dfe3f8dc9c24de6127f4.png   \n",
       "11531         1  be340ee72689dfe3f8dc9c24de6127f4.png   \n",
       "11532         1  be340ee72689dfe3f8dc9c24de6127f4.png   \n",
       "11533         1  be340ee72689dfe3f8dc9c24de6127f4.png   \n",
       "\n",
       "                          image_doi  cell_id  \\\n",
       "0      10.6084/m9.figshare.12230906        1   \n",
       "1      10.6084/m9.figshare.12230906        2   \n",
       "2      10.6084/m9.figshare.12230906        3   \n",
       "3      10.6084/m9.figshare.12230906        4   \n",
       "4      10.6084/m9.figshare.12230906        5   \n",
       "...                             ...      ...   \n",
       "11529  10.6084/m9.figshare.12229511    11530   \n",
       "11530  10.6084/m9.figshare.12229511    11531   \n",
       "11531  10.6084/m9.figshare.12229511    11532   \n",
       "11532  10.6084/m9.figshare.12229511    11533   \n",
       "11533  10.6084/m9.figshare.12229511    11534   \n",
       "\n",
       "                           bethesda_system  nucleus_x  nucleus_y  \n",
       "0                                      SCC        792        462  \n",
       "1                                      SCC        601        678  \n",
       "2                                      SCC        363        467  \n",
       "3                                      SCC        599        437  \n",
       "4      Negative for intraepithelial lesion       1186        450  \n",
       "...                                    ...        ...        ...  \n",
       "11529                                 LSIL        618        407  \n",
       "11530                                 LSIL        607        374  \n",
       "11531                                 LSIL        707        251  \n",
       "11532                                 LSIL        579        246  \n",
       "11533  Negative for intraepithelial lesion        227        130  \n",
       "\n",
       "[11534 rows x 7 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11534, 7)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando o x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for index, row in data_frame.iterrows():\n",
    "    x.append(os.path.join(image_directory, row['bethesda_system'], \"{}.png\".format(row['cell_id'])))\n",
    "x = pandas.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11534,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando o y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T22:07:32.231453Z",
     "start_time": "2024-05-27T22:07:32.227388Z"
    }
   },
   "outputs": [],
   "source": [
    "y = data_frame.iloc[:, 4].values\n",
    "label_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T22:07:32.237687Z",
     "start_time": "2024-05-27T22:07:32.233211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 3, 3, 4])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando o conjunto de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T22:07:32.245398Z",
     "start_time": "2024-05-27T22:07:32.239332Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/home/henrique/Repositorios_Git/GitHub.com/Henriquemcc/Ciencia da Computacao/Trabalho_Pratico_-_Processamento_e_Analise_de_Imagens_-_2024-1/develop_henrique_2024_05_27/dataset_converted/HSIL/8368.png'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicando o ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construindo o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tensorflow.keras.layers.Input(shape=(100, 100, 3))\n",
    "modelo_base = tensorflow.keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "mbo = modelo_base.output\n",
    "mbo = tensorflow.keras.layers.GlobalAveragePooling2D()(mbo)\n",
    "mbo = tensorflow.keras.layers.Dense(1024, activation='relu')(mbo)\n",
    "predicoes = tensorflow.keras.layers.Dense(num_classes, activation='softmax')(mbo)\n",
    "\n",
    "modelo = tensorflow.keras.models.Model(inputs=modelo_base.input, outputs=predicoes)\n",
    "\n",
    "for layer in modelo_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T22:07:34.595301Z",
     "start_time": "2024-05-27T22:07:32.248135Z"
    }
   },
   "outputs": [],
   "source": [
    "modelo.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'recall', 'precision'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessar_imagem(imagem):\n",
    "    if isinstance(imagem, numpy.ndarray):\n",
    "        imagem = imagem/255.0\n",
    "    else:\n",
    "        raise ValueError(\"Imagem deve ser um numpy array\")\n",
    "    \n",
    "    imagem = tensorflow.convert_to_tensor(imagem, dtype=tensorflow.float32)\n",
    "    imagem = tensorflow.expand_dims(imagem, axis=0)\n",
    "    return imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T22:08:47.907925Z",
     "start_time": "2024-05-27T22:08:47.844796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.0000e+00 - loss: 3.2265 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.5294 - precision: 1.0000 - recall: 1.0000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.0000e+00 - loss: 3.3644 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.6589 - precision: 1.0000 - recall: 1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m label \u001b[38;5;241m=\u001b[39m tensorflow\u001b[38;5;241m.\u001b[39mconvert_to_tensor(label, dtype\u001b[38;5;241m=\u001b[39mtensorflow\u001b[38;5;241m.\u001b[39mint8)\n\u001b[1;32m      7\u001b[0m label \u001b[38;5;241m=\u001b[39m tensorflow\u001b[38;5;241m.\u001b[39mexpand_dims(label, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagem_preprocessada\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/home/henrique/Repositorios_Git/GitHub.com/Henriquemcc/Ciencia da Computacao/Trabalho_Pratico_-_Processamento_e_Analise_de_Imagens_-_2024-1/develop_henrique_2024_05_27/venv/lib64/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/mnt/home/henrique/Repositorios_Git/GitHub.com/Henriquemcc/Ciencia da Computacao/Trabalho_Pratico_-_Processamento_e_Analise_de_Imagens_-_2024-1/develop_henrique_2024_05_27/venv/lib64/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:312\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    310\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m    314\u001b[0m         logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n",
      "File \u001b[0;32m/mnt/home/henrique/Repositorios_Git/GitHub.com/Henriquemcc/Ciencia da Computacao/Trabalho_Pratico_-_Processamento_e_Analise_de_Imagens_-_2024-1/develop_henrique_2024_05_27/venv/lib64/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:645\u001b[0m, in \u001b[0;36mTFEpochIterator.enumerate_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 645\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches:\n\u001b[1;32m    647\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\n\u001b[1;32m    648\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution\n\u001b[1;32m    649\u001b[0m         ):\n",
      "File \u001b[0;32m/mnt/home/henrique/Repositorios_Git/GitHub.com/Henriquemcc/Ciencia da Computacao/Trabalho_Pratico_-_Processamento_e_Analise_de_Imagens_-_2024-1/develop_henrique_2024_05_27/venv/lib64/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:501\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    500\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/home/henrique/Repositorios_Git/GitHub.com/Henriquemcc/Ciencia da Computacao/Trabalho_Pratico_-_Processamento_e_Analise_de_Imagens_-_2024-1/develop_henrique_2024_05_27/venv/lib64/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:705\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    701\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    704\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 705\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/mnt/home/henrique/Repositorios_Git/GitHub.com/Henriquemcc/Ciencia da Computacao/Trabalho_Pratico_-_Processamento_e_Analise_de_Imagens_-_2024-1/develop_henrique_2024_05_27/venv/lib64/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:744\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    741\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    742\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[1;32m    743\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[0;32m--> 744\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/home/henrique/Repositorios_Git/GitHub.com/Henriquemcc/Ciencia da Computacao/Trabalho_Pratico_-_Processamento_e_Analise_de_Imagens_-_2024-1/develop_henrique_2024_05_27/venv/lib64/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3478\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3477\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3478\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3479\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3481\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index, image_path in enumerate(x_train):\n",
    "    if (os.path.exists(image_path)):\n",
    "        imagem_rgb = ImagemRGB.from_file(image_path)\n",
    "        imagem_preprocessada = preprocessar_imagem(imagem_rgb.matriz)\n",
    "        label = tensorflow.keras.utils.to_categorical(y_train[index], num_classes)\n",
    "        label = tensorflow.convert_to_tensor(label, dtype=tensorflow.int8)\n",
    "        label = tensorflow.expand_dims(label, axis=0)\n",
    "        modelo.fit(x=numpy.array(imagem_preprocessada), y=label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
